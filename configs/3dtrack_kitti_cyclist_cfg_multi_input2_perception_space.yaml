# dataset configs

dataset_cfg:
  dataset_type: KITTIFull
  data_root_dir: ./data/kitti/training/
  category_name: Cyclist
  cache_train: True
  cache_eval: False
  coordinate_mode: camera
  preload_offset: 10
  num_candidates_per_frame: 4
  search_npts: 1024
  search_offset: 2.0
  search_offset2: 0.0
  search_scale: 1.0
  template_set_size: 2 # New
  template_npts: 1024
  template_offset: 2.0
  template_offset2: 0.0
  template_scale: 1.0
  model_scale: 1.25
  model_offset: 0.0
  offset_max: [3., 10., 10.]
  up_axis: [0,-1,0]
  degree: True 
  train_cfg:
    use_z: True
    use_augmentation: False
  eval_cfg:
    use_z: True
    reference_bbox: previous_pred

# model configs

model_cfg:
  model_type: TDTrack_Multi_Input_Perception_Space
  
  backbone_cfg:
    type: DGCNN
    layers_cfg:
      - {
        mlps: [0, 64, 64, 64],
        use_xyz: True,
        sample_method: Range,
        nsample: 32,
      }
      - {
        mlps: [64, 128, 128, 128],
        use_xyz: True,
        sample_method: Range,
        nsample: 32,
      }
      - {
        mlps: [128, 256, 256, 256],
        use_xyz: True,
        sample_method: Range,
        nsample: 32,
      }
    out_channels: 256
    downsample_ratios: [2,4,8]
  
  transformer_cfg:
    feat_dim: [256, 256] # Consistent with template_set_size
    mask_radii: False
    layers_cfg: 
      - {
        type: attn,
        feat_dim: 256,
        num_heads: 1,
        attn_dropout: 0.1,
        norm: 'layer_norm',
        ffn_cfg: {
          hidden_dim: 256,
          activation: 'relu',
          dropout: 0.1,
          use_bias: True,
          norm: 'layer_norm'
        },
        pos_emb_cfg: {
          type: mlp
        },
        mask_emb: mask_trfm,        
        mask_pred: true,
        center_pred: true,
        dropout: 0.1
      }
      - {
        type: attn,
        feat_dim: 256,
        num_heads: 2,
        attn_dropout: 0.1,
        norm: 'layer_norm',
        ffn_cfg: {
          hidden_dim: 256,
          activation: 'relu',
          dropout: 0.1,
          use_bias: True,
          norm: 'layer_norm'
        },
        pos_emb_cfg: {
          type: mlp
        },
        mask_emb: mask_trfm,
        mask_pred: true,
        center_pred: true,
        dropout: 0.1
      }
      - {
        type: attn,
        feat_dim: 256,
        num_heads: 4,
        attn_dropout: 0.1,
        norm: 'layer_norm',
        ffn_cfg: {
          hidden_dim: 256,
          activation: 'relu',
          dropout: 0.1,
          use_bias: True,
          norm: 'layer_norm'
        },
        pos_emb_cfg: {
          type: mlp
        },
        mask_emb: mask_trfm,        
        mask_pred: true,
        center_pred: true,
        dropout: 0.1
      }
      - {
        type: attn,
        feat_dim: 256,
        num_heads: 8,
        attn_dropout: 0.1,
        norm: 'layer_norm',
        ffn_cfg: {
          hidden_dim: 256,
          activation: 'relu',
          dropout: 0.1,
          use_bias: True,
          norm: 'layer_norm'
        },
        pos_emb_cfg: {
          type: mlp
        },
        mask_emb: mask_trfm,
        mask_pred: true,
        center_pred: true,
        dropout: 0.1
      }

  exrpn_cfg:
    feat_dim: 256
    transformer_cfg:
      layers_cfg:
      - type: attn
        radius: 0.3
        feat_dim: 256
        num_heads: 1
        attn_dropout: 0.1
        norm: layer_norm
        pos_emb_cfg:
          type: mlp
        mask_emb: mask_trfm
        center_emb: true
        dropout: 0.1
        sigma_n2: 0.1
        fixed_sigma_n2: False
#  srpn_cfg:
#    feat_dim: [256, 256, 256]   # vote

# task configs
task_type: TDTrackTask_Multi_Input_Perception

# optimizer & scheduler configs
optimizer_cfg:
  optimizer_type: Adam
  lr: 0.001  
  weight_decay: 0
  betas: [0.5, 0.999]
  eps: 1.0e-6

scheduler_cfg:
  scheduler_type: StepLR
  step_size: 10
  gamma: 0.2

loss_cfg:
  cascaded_center_loss_func: smooth_l1
  refined_loss_func: smooth_l1
  cascaded_center_weight: 1.0
  cascaded_mask_weight: 0.02
  refined_mask_weight: 1.5
  refined_box_weight: 1.0

# train & eval configs

train_cfg:
  max_epochs: 50
  batch_size: 60
  num_workers: 4
  save_per_epoch: 10
  save_top_k: 3
  val_per_epoch: 1

eval_cfg:
  batch_size: 1
  num_workers: 4
  iou_space: 3 